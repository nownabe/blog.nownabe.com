<!DOCTYPE html><html><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><meta charset="utf-8"><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta content="width=device-width, initial-scale=1" name="viewport"><title>nownab.log | 統計学入門  第9章 標本分布</title><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" /><link href="/styles/ress.min.css" rel="stylesheet"><link href="/styles/font-awesome.min.css" rel="stylesheet"><link href="/styles/index.css" rel="stylesheet"><link href="/styles/highlight.css" rel="stylesheet"><link href="/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.ico"><meta content="nownab.log" property="og:site_name"><meta content="article" property="og:type"><meta content="summary" property="twitter:card"><meta content="@nownabe" property="twitter:site"><meta content="@nownabe" property="twitter:creator"><meta content="https://blog.nownabe.com/images/nownabe.png" property="twitter:image"><meta content="1775541316016693" property="fb:app_id"><meta content="統計学入門  第9章 標本分布" property="og:title"><meta content=" nownab.log | 統計学入門 第8章 大数の法則と中心極限定理         統計学入門 (基礎統計学Ⅰ)     東京大学教養学部統計学教室   東京大学出版会             機械学習勉強会として今は 統計学入門 をやっている。  週一でやっていて、今週から輪読形式で進めてみることになった。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/ml-statistics-intro: 基礎統計学 I 統計学入門 (東京大学出版会) " property="og:description"><meta content="https://blog.nownabe.com/images/nownabe.png" property="og:image"><meta content="https://blog.nownabe.com/2017/09/22/1126.html" property="og:url"><meta content=" nownab.log | 統計学入門 第8章 大数の法則と中心極限定理         統計学入門 (基礎統計学Ⅰ)     東京大学教養学部統計学教室   東京大学出版会             機械学習勉強会として今は 統計学入門 をやっている。  週一でやっていて、今週から輪読形式で進めてみることになった。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/ml-statistics-intro: 基礎統計学 I 統計学入門 (東京大学出版会) " property="twitter:description"><meta content="統計学入門  第9章 標本分布" property="twitter:title"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37580164-4', 'auto');
ga('send', 'pageview');</script></head><body><div id="site-container"><div id="header-container"><header class="container" role="banner"><h1><a href="/"><img alt="now" src="/images/nownabe.svg">nownab.log</a></h1><p>nownab.log is the life log of nownabe</p></header></div><div id="content-container"><div class="container" id="content" role="main"><article><div class="title"><h1><a href="/2017/09/22/1126.html">統計学入門  第9章 標本分布</a></h1><span class="date">Posted on&nbsp;Sep 10, 2017</span></div><div class="body"><p><a href="https://blog.nownabe.com/2017/09/10/1105.html">nownab.log | 統計学入門 第8章 大数の法則と中心極限定理</a></p>

<div class="asin">
<div class="asin-image"><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/" rel="nofollow noopener" target="_blank"><img src="http://images-jp.amazon.com/images/P/4130420658.09._SL160_.jpg" alt="統計学入門 (基礎統計学Ⅰ)" title="統計学入門 (基礎統計学Ⅰ)"></a></div>
<div class="asin-detail">
<p><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/" rel="nofollow noopener" target="_blank">統計学入門 (基礎統計学Ⅰ)</a></p>
<ul>
<li>東京大学教養学部統計学教室</li>
<li>東京大学出版会</li>
</ul>
</div>

<p></p>

<p></p>
</div>

<p>機械学習勉強会として今は<a href="https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/" rel="nofollow noopener" target="_blank">統計学入門</a>をやっている。<br>
週一でやっていて、今週から輪読形式で進めてみることになった。</p>

<p>また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。<br>
<a href="https://github.com/Wondershake/ml-statistics-intro" rel="nofollow noopener" target="_blank">Wondershake/ml-statistics-intro: 基礎統計学 I 統計学入門 (東京大学出版会)</a></p>

<h1>
<span id="今回の内容" class="fragment"></span><a href="#%E4%BB%8A%E5%9B%9E%E3%81%AE%E5%86%85%E5%AE%B9"><i class="fa fa-link"></i></a>今回の内容</h1>

<ul>
<li>
<strong>記述統計学 (descriptive statistics)</strong>

<ul>
<li>2, 3章でやったもの</li>
<li>分析対象とする集団の属性について完全に知ることができる場合</li>
</ul>
</li>
<li>
<strong>標本抽出</strong>: 分析対象となるサンプルをランダムに選ぶ</li>
<li>
<strong>全数調査</strong>あるいは(<strong>悉皆調査</strong>): 集団全体を調査する</li>
</ul>

<h2>
<span id="91-母集団と標本" class="fragment"></span><a href="#91-%E6%AF%8D%E9%9B%86%E5%9B%A3%E3%81%A8%E6%A8%99%E6%9C%AC"><i class="fa fa-link"></i></a>9.1 母集団と標本</h2>

<ul>
<li>われわれが知りたいのは<strong>母集団 (population)</strong>だが、母集団を直接知るのは難しい場合がある</li>
<li>日本人の意識調査を行う場合は日本人全体が母集団</li>
<li>
<strong>統計的推測 (statistical inference)</strong>

<ul>
<li>母集団から一部を選び出し</li>
<li>それを分析し</li>
<li>母集団について推測する</li>
</ul>
</li>
<li>
<strong>標本 (sample)</strong>: 分析のために母集団から選び出された要素</li>
<li>
<strong>標本抽出 (sampling)</strong>: 標本を選び出すこと</li>
</ul>

<h3>
<span id="911-母集団と母集団分布" class="fragment"></span><a href="#911-%E6%AF%8D%E9%9B%86%E5%9B%A3%E3%81%A8%E6%AF%8D%E9%9B%86%E5%9B%A3%E5%88%86%E5%B8%83"><i class="fa fa-link"></i></a>9.1.1 母集団と母集団分布</h3>

<ul>
<li>
<strong>母集団分布 (population distribution)</strong>: 母集団の分布。これを知ればよい</li>
<li>標本$X_i$は母集団分布$f(x)$に従う独立な確率変数と考えられる</li>
<li>統計学では無限母集団を考えることが多いので、ヒストグラムや相対頻度よりも確率分布$f(x)$を考えることが多い</li>
</ul>

<h3>
<span id="912-母集団分布の母数" class="fragment"></span><a href="#912-%E6%AF%8D%E9%9B%86%E5%9B%A3%E5%88%86%E5%B8%83%E3%81%AE%E6%AF%8D%E6%95%B0"><i class="fa fa-link"></i></a>9.1.2 母集団分布の母数</h3>

<ul>
<li>母集団分布が理論的または経験的にある知られた確率分布(正規分布やポアソン分布)だとわかっている場合、その確率分布のパラメータさえわかれば母集団分布のすべてを知ることができる

<ul>
<li>正規分布なら$\mu$と$\sigma^2$、ポアソン分布なら$\lambda$</li>
<li>このパラメータを<strong>母数 (parameter)</strong>という</li>
<li>このような場合を<strong>パラメトリック</strong>という</li>
</ul>
</li>
<li>
<strong>ノン・パラメトリック (nonparametric)</strong>

<ul>
<li>いくつかのパラメータで母集団分布を決定することができない場合</li>
<li>平均、メディアン、モード、分散、レンジ、歪度、尖度などを考える</li>
</ul>
</li>
</ul>

<h3>
<span id="913-標本の抽出" class="fragment"></span><a href="#913-%E6%A8%99%E6%9C%AC%E3%81%AE%E6%8A%BD%E5%87%BA"><i class="fa fa-link"></i></a>9.1.3 標本の抽出</h3>

<ul>
<li>
<strong>復元抽出 (sampling with replacement)</strong>: 抽出した要素を再び母集団に戻し、その後の抽出の対象とする</li>
<li>
<strong>非復元抽出 (sampling without replacement)</strong>: 抽出した要素を戻さない。本書ではこちらのみを扱う</li>
<li>母集団の大きさ$N$が標本の大きさ$n$に比べて十分大きい場合はほとんど差がない</li>
<li>$N$個の母集団から$n$個の標本の可能な選び方の総数は

<ul>
<li>${}_NC_n=\frac{N!}{n!(N-n)!}$</li>
</ul>
</li>
<li>
<strong>単純ランダム・サンプリング</strong> (単純無作為抽出)

<ul>
<li>母集団の各要素が標本に選ばれる確率を等しく$\frac{n}{N}$とする</li>
<li>本書ではこの抽出方法のみを考える</li>
</ul>
</li>
</ul>

<h2>
<span id="92-母数と統計量" class="fragment"></span><a href="#92-%E6%AF%8D%E6%95%B0%E3%81%A8%E7%B5%B1%E8%A8%88%E9%87%8F"><i class="fa fa-link"></i></a>9.2 母数と統計量</h2>

<h3>
<span id="921-統計量" class="fragment"></span><a href="#921-%E7%B5%B1%E8%A8%88%E9%87%8F"><i class="fa fa-link"></i></a>9.2.1 統計量</h3>

<ul>
<li>
<strong>母平均 (population mean)</strong>

<ul>
<li>代表的な母数</li>
<li>$/mu=\int_{-\infty}^\infty xf(x)dx$あるいは$\mu=\sum_xxf(x)$</li>
<li>
<strong>母分散 (population variance)</strong> $\sigma^2$も同じように定まる</li>
</ul>
</li>
<li>
<strong>標本平均</strong>

<ul>
<li>$\bar{X}=\frac{X_1+X_2+\dots+X_n}/n$</li>
<li>母平均を直接知るのは難しいから標本平均を用いる</li>
<li>$E(\bar{X})=\mu$</li>
<li>大数の法則から$n$が大きくなるに連れ$\bar{X}\rightarrow\mu$</li>
</ul>
</li>
<li>
<strong>統計量 (statistic)</strong>

<ul>
<li>標本平均のように、標本を要約して母集団の母数の推測に使われるもの</li>
<li>標本の平均、分散、標準偏差、メディアン、最小値、最大値、相関係数など</li>
<li>$t(X_1, \dots, X_n)$で表せる</li>
<li>この確率分布は母集団分布から求められる</li>
<li>統計量の値の出方から母集団分布が求められる</li>
<li>統計量の確率分布をその統計量の<strong>標本分布 (sampling distribution)</strong>という</li>
</ul>
</li>
</ul>

<h3>
<span id="922-標本平均と標本分散" class="fragment"></span><a href="#922-%E6%A8%99%E6%9C%AC%E5%B9%B3%E5%9D%87%E3%81%A8%E6%A8%99%E6%9C%AC%E5%88%86%E6%95%A3"><i class="fa fa-link"></i></a>9.2.2 標本平均と標本分散</h3>

<ul>
<li>母数でも特に重要なのが母平均$\mu$と母分散$\sigma^2$</li>
<li>
<strong>標本平均 (sample mean)</strong>

<ul>
<li>$\bar{X}=\frac{X_1+X_2+\dots+X_n}{n}$</li>
<li>$E(\bar{X})=\mu$</li>
<li>$V(\bar{X})=\frac{\sigma^2}{n}$</li>
</ul>
</li>
<li>
<strong>標本分散 (sample variance)</strong>

<ul>
<li>$s^2=\frac{1}{n-1}\{(X_1-\bar{X})^2+(<em>2-\bar{X})^2+\dots+(X</em>n-\bar{X})^2\}$</li>
<li>$E(s^2)=\sigma^2$</li>
<li>母分散に対して偏りがないので<strong>不偏分散 (unbiased variance)</strong>という</li>
<li>$S^2=\frac{1}{n}\{(X_1-\bar{X})^2+(_2-\bar{X})^2+\dots+(X_n-\bar{X})^2\}$は$E(S^2)=\frac{n-1}{n}\sigma^2$となり偏る</li>
<li>$n-1$には<strong>自由度 (degree of freedom)</strong>という名前がついている</li>
</ul>
</li>
</ul>

<h2>
<span id="93-統計量の標本分布" class="fragment"></span><a href="#93-%E7%B5%B1%E8%A8%88%E9%87%8F%E3%81%AE%E6%A8%99%E6%9C%AC%E5%88%86%E5%B8%83"><i class="fa fa-link"></i></a>9.3 統計量の標本分布</h2>

<h3>
<span id="931-標本分布の役割" class="fragment"></span><a href="#931-%E6%A8%99%E6%9C%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%BD%B9%E5%89%B2"><i class="fa fa-link"></i></a>9.3.1 標本分布の役割</h3>

<h3>
<span id="932-標本和の標本分布" class="fragment"></span><a href="#932-%E6%A8%99%E6%9C%AC%E5%92%8C%E3%81%AE%E6%A8%99%E6%9C%AC%E5%88%86%E5%B8%83"><i class="fa fa-link"></i></a>9.3.2 標本和の標本分布</h3>

<ul>
<li>標本和$X_1+X_2+\dots+X_3$や標本平均$\bar{X}$の標本分布は母集団分布に依存する</li>
<li>パラメトリックで分布が再生性を持っていれば簡単に求められる

<ul>
<li>二項分布</li>
<li>ポアソン分布</li>
<li>正規分布</li>
<li>など</li>
</ul>
</li>
<li>
<strong>漸近的 (asymptotic)</strong>

<ul>
<li>$n\rightarrow\infty$のとき成り立つこと</li>
<li>標本分布を求めるためには重積分が必要なので中心極限定理によって近似的に分布を求めることが多い</li>
<li>標本平均$\bar{X}$の漸近分布が$N(\mu, \frac{\sigma^2}{n})$に従う</li>
</ul>
</li>
</ul>

<h2>
<span id="94-有限母集団と有限母集団修正" class="fragment"></span><a href="#94-%E6%9C%89%E9%99%90%E6%AF%8D%E9%9B%86%E5%9B%A3%E3%81%A8%E6%9C%89%E9%99%90%E6%AF%8D%E9%9B%86%E5%9B%A3%E4%BF%AE%E6%AD%A3"><i class="fa fa-link"></i></a>9.4 有限母集団と有限母集団修正</h2>

<ul>
<li>母集団の大きさ$N$が大きくない場合や$n/N$が大きい場合、有限母集団を考えた修正が必要</li>
<li>$V(\bar{X})=\frac{N-n}{N-1}\frac{\sigma^2}{n}$</li>
<li><strong>有限母集団修正</strong></li>
</ul>

<h1>
<span id="練習問題" class="fragment"></span><a href="#%E7%B7%B4%E7%BF%92%E5%95%8F%E9%A1%8C"><i class="fa fa-link"></i></a>練習問題</h1>

<p><a href="https://github.com/Wondershake/ml-statistics-intro/issues/17" rel="nofollow noopener" target="_blank">第9章 標本分布 · Issue #17 · Wondershake/ml-statistics-intro</a></p>

<h1>
<span id="所感" class="fragment"></span><a href="#%E6%89%80%E6%84%9F"><i class="fa fa-link"></i></a>所感</h1>

<ul>
<li>よく聞くノン・パラメトリックが何かを知ることができてよかった</li>
</ul>

<h1>
<span id="次回" class="fragment"></span><a href="#%E6%AC%A1%E5%9B%9E"><i class="fa fa-link"></i></a>次回</h1>

<p>第10章 正規分布からの標本</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
</pre></div></div>
</div><div class="sns-buttons"><ul><li><div class="twitter-button"><a class="twitter-share-button" data-related="nownabe" data-via="nownabe" href="https://twitter.com/share">Tweet</a></div></li><li><div class="fb-like" data-action="like" data-layout="button_count" data-share="true" data-show-faces="false" data-size="small"></div></li><li><a class="tumblr-share-button" href="https://www.tumblr.com/share"></a></li><li><a class="hatena-bookmark-button" data-hatena-bookmark-lang="ja" data-hatena-bookmark-layout="standard-balloon" href="http://b.hatena.ne.jp/entry/" title="このエントリーをはてなブックマークに追加"><img alt="このエントリーをはてなブックマークに追加" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20"></a></li><li><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></li></ul></div></article></div></div><div id="footer-container"><footer class="container"><p class="copyright">Copyright &copy; 2016<img alt="now" src="/images/nownabe.svg">nownabe All Right Reserved.</p></footer><aside class="container" id="information"><ul id="links"><li><a href="https://nownabe.github.io"><img alt="nownabe.github.io" src="/images/nownabe.svg"></a></li><li><a href="https://github.com/nownabe"><img alt="github.com/nownabe" src="/images/github.svg"></a></li><li><a href="https://qiita.com/nownabe"><img alt="qiita.com/nownabe" src="/images/qiita.svg"></a></li><li><a href="https://twitter.com/nownabe"><img alt="twitter.com/nownabe" src="/images/twitter.svg"></a></li><li><a href="https://www.facebook.com/nownabe"><img alt="www.facebook.com/nownabe" src="/images/facebook.png"></a></li></ul></aside><div class="container"><p>今が最高</p></div></div><div id="fb-root"></div></div><script>// Twitter
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><script>// Facebook
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.7&appId=1775541316016693";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script><script>// Pocket
!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js"></script></body></html>