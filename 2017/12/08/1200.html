<!DOCTYPE html><html><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><meta charset="utf-8"><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta content="width=device-width, initial-scale=1" name="viewport"><title>nownab.log | Pythonではじめる機械学習  5回目</title><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" /><link href="/styles/ress.min.css" rel="stylesheet"><link href="/styles/font-awesome.min.css" rel="stylesheet"><link href="/styles/index.css" rel="stylesheet"><link href="/styles/highlight.css" rel="stylesheet"><link href="/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.ico"><meta content="nownab.log" property="og:site_name"><meta content="article" property="og:type"><meta content="summary" property="twitter:card"><meta content="@nownabe" property="twitter:site"><meta content="@nownabe" property="twitter:creator"><meta content="https://blog.nownabe.com/images/nownabe.png" property="twitter:image"><meta content="1775541316016693" property="fb:app_id"><meta content="Pythonではじめる機械学習  5回目" property="og:title"><meta content=" nownab.log | Pythonではじめる機械学習 4回目     週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/machine-learning-study: 機械学習勉強会   この記事は資料作りの下書き的扱い。     4章 データの表現と特徴量エンジニアリング     4.5 自動特徴量選択     特徴量を追加するとモデルは複雑に...   " property="og:description"><meta content="https://blog.nownabe.com/images/nownabe.png" property="og:image"><meta content="https://blog.nownabe.com/2017/12/08/1200.html" property="og:url"><meta content=" nownab.log | Pythonではじめる機械学習 4回目     週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/machine-learning-study: 機械学習勉強会   この記事は資料作りの下書き的扱い。     4章 データの表現と特徴量エンジニアリング     4.5 自動特徴量選択     特徴量を追加するとモデルは複雑に...   " property="twitter:description"><meta content="Pythonではじめる機械学習  5回目" property="twitter:title"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37580164-4', 'auto');
ga('send', 'pageview');</script></head><body><div id="site-container"><div id="header-container"><header class="container" role="banner"><h1><a href="/"><img alt="now" src="/images/nownabe.svg">nownab.log</a></h1><p>nownab.log is the life log of nownabe</p></header></div><div id="content-container"><div class="container" id="content" role="main"><article><div class="title"><h1><a href="/2017/12/08/1200.html">Pythonではじめる機械学習  5回目</a></h1><span class="date">Posted on&nbsp;Nov 27, 2017</span></div><div class="body"><p><a href="https://blog.nownabe.com/2017/12/08/1199.html">nownab.log | Pythonではじめる機械学習 4回目</a></p>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=nownabe0c-22&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=4873117984&amp;linkId=05656b0761603e4e9f88423f102e42c6"></iframe>

<p>週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。</p>

<p>また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。<br>
<a href="https://github.com/Wondershake/machine-learning-study" rel="nofollow noopener" target="_blank">Wondershake/machine-learning-study: 機械学習勉強会</a></p>

<p>この記事は資料作りの下書き的扱い。</p>

<h1>
<span id="4章-データの表現と特徴量エンジニアリング" class="fragment"></span><a href="#4%E7%AB%A0-%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%A1%A8%E7%8F%BE%E3%81%A8%E7%89%B9%E5%BE%B4%E9%87%8F%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0"><i class="fa fa-link"></i></a>4章 データの表現と特徴量エンジニアリング</h1>

<h2>
<span id="45-自動特徴量選択" class="fragment"></span><a href="#45-%E8%87%AA%E5%8B%95%E7%89%B9%E5%BE%B4%E9%87%8F%E9%81%B8%E6%8A%9E"><i class="fa fa-link"></i></a>4.5 自動特徴量選択</h2>

<ul>
<li>特徴量を追加するとモデルは複雑になり過学習の可能性が高くなる</li>
<li>最も有用な特徴量を選択して残りを捨てると汎化性能が向上する

<ul>
<li>新しい特徴量を加えるとき</li>
<li>高次元データセットの場合</li>
</ul>
</li>
<li>3つの戦略

<ul>
<li><strong>単変量統計 (univariate statistics)</strong></li>
<li><strong>モデルベース選択 (model-based selection)</strong></li>
<li><strong>反復選択 (iterative selection)</strong></li>
</ul>
</li>
<li>これらの方法はすべて教師あり手法</li>
<li>実世界のデータでは特徴量選択で大幅に性能が向上することはあまりない</li>
</ul>

<h3>
<span id="451-単変量統計" class="fragment"></span><a href="#451-%E5%8D%98%E5%A4%89%E9%87%8F%E7%B5%B1%E8%A8%88"><i class="fa fa-link"></i></a>4.5.1 単変量統計</h3>

<ul>
<li>ターゲットとの間に統計的な関係が顕著な個々の特徴量を選択する</li>
<li><strong>分散分析 (analysis of variance: ANOVA)</strong></li>
<li>個々の特徴量を個別に考慮するので、複数組み合わさって意味のある特徴量は捨てられる</li>
<li>計算が高速</li>
</ul>

<h3>
<span id="452-モデルベース特徴量選択" class="fragment"></span><a href="#452-%E3%83%A2%E3%83%87%E3%83%AB%E3%83%99%E3%83%BC%E3%82%B9%E7%89%B9%E5%BE%B4%E9%87%8F%E9%81%B8%E6%8A%9E"><i class="fa fa-link"></i></a>4.5.2 モデルベース特徴量選択</h3>

<ul>
<li>学習済みの教師あり学習モデルにおける特徴量の重要度から選択する

<ul>
<li>RandomForestの重要性</li>
<li>正則化を施した線形モデルの係数</li>
</ul>
</li>
</ul>

<h3>
<span id="453-反復特徴量選択" class="fragment"></span><a href="#453-%E5%8F%8D%E5%BE%A9%E7%89%B9%E5%BE%B4%E9%87%8F%E9%81%B8%E6%8A%9E"><i class="fa fa-link"></i></a>4.5.3 反復特徴量選択</h3>

<ul>
<li>一連の教師あり学習モデルを学習して特徴量を選択する

<ul>
<li>0次元から1次元ずつ特徴量を加えていく方法</li>
<li>全特徴量から1つずつ削っていく方法</li>
</ul>
</li>
<li>**再帰的特徴量削減 (recursive feature elimination: RFE)

<ul>
<li>すべての特徴量からモデルを作る</li>
<li>最も重要度が低い特徴量を削除する</li>
<li>特徴量が指定された数になるまで繰り返す</li>
</ul>
</li>
</ul>

<h2>
<span id="46-専門家知識の利用" class="fragment"></span><a href="#46-%E5%B0%82%E9%96%80%E5%AE%B6%E7%9F%A5%E8%AD%98%E3%81%AE%E5%88%A9%E7%94%A8"><i class="fa fa-link"></i></a>4.6 専門家知識の利用</h2>

<ul>
<li>特徴量エンジニアリングに<strong>専門家知識 (expert knowledge)</strong>を用いることがある</li>
<li>例では、曜日周期性、時間周期性のある回帰問題で次のように特徴量を増やしていった

<ul>
<li>Unixtime</li>
<li>1日の中での時刻</li>
<li>1日の中での時刻 + 曜日</li>
<li>(1日の中での時刻 + 曜日)のOneHot表現</li>
<li>(1日の中での時刻 + 曜日)のOneHot表現の交互作用特徴量</li>
</ul>
</li>
</ul>

<h2>
<span id="47-まとめと展望" class="fragment"></span><a href="#47-%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A8%E5%B1%95%E6%9C%9B"><i class="fa fa-link"></i></a>4.7 まとめと展望</h2>

<ul>
<li>機械学習アルゴリズムに適したデータ表現が重要

<ul>
<li>ワンホットエンコーディング</li>
</ul>
</li>
<li>特徴量の追加

<ul>
<li>専門家知識</li>
</ul>
</li>
<li>線形モデルはビニング、多項式特徴量、交互作用特徴量の追加の恩恵を受けやすい</li>
<li>ランダムフォレストやSVMや特徴量空間の拡張なしで複雑なモデルを学習できる</li>
</ul>

<h1>
<span id="5章-モデルの評価と改良" class="fragment"></span><a href="#5%E7%AB%A0-%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E8%A9%95%E4%BE%A1%E3%81%A8%E6%94%B9%E8%89%AF"><i class="fa fa-link"></i></a>5章 モデルの評価と改良</h1>

<h2>
<span id="51-交差検証" class="fragment"></span><a href="#51-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.1 交差検証</h2>

<ul>
<li>
<strong>交差検証 (cross-validation)</strong>

<ul>
<li>汎化性能を評価する手法</li>
</ul>
</li>
<li>
<strong>k分割交差検証 (k-fold cross-validation)</strong>がよく用いられる

<ul>
<li>データセットをk個に分割し、順に1つの分割をテストデータとし、残りのk-1個の分割を訓練データとする</li>
</ul>
</li>
</ul>

<h3>
<span id="511-scikit-learnでの交差検証" class="fragment"></span><a href="#511-scikit-learn%E3%81%A7%E3%81%AE%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.1.1 scikit-learnでの交差検証</h3>

<ul>
<li>
<code>cross_val_score</code>関数で交差検証できる</li>
</ul>

<h3>
<span id="512-交差検証の利点" class="fragment"></span><a href="#512-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%AE%E5%88%A9%E7%82%B9"><i class="fa fa-link"></i></a>5.1.2 交差検証の利点</h3>

<ul>
<li>すべてのデータが正確に1度だけテストされる</li>
<li>計算コストは単純にk倍になる</li>
</ul>

<h3>
<span id="513-層化k分割交差検証と他の戦略" class="fragment"></span><a href="#513-%E5%B1%A4%E5%8C%96k%E5%88%86%E5%89%B2%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%A8%E4%BB%96%E3%81%AE%E6%88%A6%E7%95%A5"><i class="fa fa-link"></i></a>5.1.3 層化k分割交差検証と他の戦略</h3>

<ul>
<li>
<strong>層化k分割交差検証 (stratified k-fold cross-validation)</strong>ではそれぞれの正解ラベルに対して均等に分割する</li>
<li>正解ラベルに対する分割の偏りをなくす</li>
<li>クラス分類では層化k分割交差検証を、回帰ではk分割交差検証を用いる</li>
</ul>

<h4>
<span id="5131-交差検証のより詳細な制御" class="fragment"></span><a href="#5131-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%AE%E3%82%88%E3%82%8A%E8%A9%B3%E7%B4%B0%E3%81%AA%E5%88%B6%E5%BE%A1"><i class="fa fa-link"></i></a>5.1.3.1 交差検証のより詳細な制御</h4>

<ul>
<li>データをシャッフルして分割するのもあり</li>
</ul>

<h4>
<span id="5132-1つ抜き交差検証" class="fragment"></span><a href="#5132-1%E3%81%A4%E6%8A%9C%E3%81%8D%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.1.3.2 1つ抜き交差検証</h4>

<ul>
<li>
<strong>1つ抜き交差検証 (leave-one-out)</strong>

<ul>
<li>サンプルの数だけ分割する</li>
<li>個々の分割が1サンプルのみ</li>
<li>毎回1サンプルのみテストする</li>
</ul>
</li>
<li>小さいデータセットでより良い推定ができる</li>
</ul>

<h4>
<span id="5133-シャッフル分割交差検証" class="fragment"></span><a href="#5133-%E3%82%B7%E3%83%A3%E3%83%83%E3%83%95%E3%83%AB%E5%88%86%E5%89%B2%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.1.3.3 シャッフル分割交差検証</h4>

<ul>
<li>
<strong>シャッフル分割交差検証 (shuffle-split cross-validation)</strong>

<ul>
<li>非常に柔軟な交差検証手法</li>
<li>分割数やテストデータの割合、使用するデータの割合、繰り返し数などを指定できる</li>
<li>層化バージョンもある</li>
</ul>
</li>
<li>一部のデータのみ使うようにすれば大きいデータに有用</li>
</ul>

<h4>
<span id="5134-グループ付き交差検証" class="fragment"></span><a href="#5134-%E3%82%B0%E3%83%AB%E3%83%BC%E3%83%97%E4%BB%98%E3%81%8D%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.1.3.4 グループ付き交差検証</h4>

<ul>
<li>未知のグループに対する予測を検証したいとき</li>
<li>例えば、

<ul>
<li>表情からの感情推定で新しい人に対する推定をする</li>
<li>新しい患者に対する推定をする</li>
</ul>
</li>
<li>それぞれのグループは分割されず、完全に訓練データかテストデータのどちらかになる</li>
</ul>

<h2>
<span id="52-グリッドサーチ" class="fragment"></span><a href="#52-%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%B5%E3%83%BC%E3%83%81"><i class="fa fa-link"></i></a>5.2 グリッドサーチ</h2>

<ul>
<li>
<strong>グリッドサーチ (grid search)</strong>

<ul>
<li>最良のパラメータを見つける方法</li>
<li>最もよく用いられる</li>
<li>すべてのパラメータの組み合わせを試す</li>
</ul>
</li>
</ul>

<h3>
<span id="521-単純なグリッドサーチ" class="fragment"></span><a href="#521-%E5%8D%98%E7%B4%94%E3%81%AA%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%B5%E3%83%BC%E3%83%81"><i class="fa fa-link"></i></a>5.2.1 単純なグリッドサーチ</h3>

<h3>
<span id="522-パラメータの過剰適合の危険性と検証セット" class="fragment"></span><a href="#522-%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%81%AE%E9%81%8E%E5%89%B0%E9%81%A9%E5%90%88%E3%81%AE%E5%8D%B1%E9%99%BA%E6%80%A7%E3%81%A8%E6%A4%9C%E8%A8%BC%E3%82%BB%E3%83%83%E3%83%88"><i class="fa fa-link"></i></a>5.2.2 パラメータの過剰適合の危険性と検証セット</h3>

<ul>
<li>グリッドサーチの検証で用いたテストデータは最終評価には使えない

<ul>
<li>そのテストデータに過剰適合してるから</li>
</ul>
</li>
<li>グリッドサーチの検証用として訓練データをさらに分割して検証データを作る</li>
</ul>

<h3>
<span id="523-交差検証を用いたグリッドサーチ" class="fragment"></span><a href="#523-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%B5%E3%83%BC%E3%83%81"><i class="fa fa-link"></i></a>5.2.3 交差検証を用いたグリッドサーチ</h3>

<ul>
<li>グリッドサーチで汎化性能をより良く見積もるために、それぞれのパラメータの組み合わせに対して交差検証を行う</li>
</ul>

<h4>
<span id="5231-交差検証の結果の解析" class="fragment"></span><a href="#5231-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%AE%E7%B5%90%E6%9E%9C%E3%81%AE%E8%A7%A3%E6%9E%90"><i class="fa fa-link"></i></a>5.2.3.1 交差検証の結果の解析</h4>

<ul>
<li>2次元のグリッドサーチならヒートマップで可視化するといい</li>
<li>グリッドサーチには適切なレンジの設定が必要</li>
</ul>

<h4>
<span id="5232-グリッドでないサーチ空間" class="fragment"></span><a href="#5232-%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%81%A7%E3%81%AA%E3%81%84%E3%82%B5%E3%83%BC%E3%83%81%E7%A9%BA%E9%96%93"><i class="fa fa-link"></i></a>5.2.3.2 グリッドでないサーチ空間</h4>

<h4>
<span id="5233-異なる交差検証手法を用いたグリッドサーチ" class="fragment"></span><a href="#5233-%E7%95%B0%E3%81%AA%E3%82%8B%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E6%89%8B%E6%B3%95%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%B5%E3%83%BC%E3%83%81"><i class="fa fa-link"></i></a>5.2.3.3 異なる交差検証手法を用いたグリッドサーチ</h4>

<h4>
<span id="5234-ネストした交差検証" class="fragment"></span><a href="#5234-%E3%83%8D%E3%82%B9%E3%83%88%E3%81%97%E3%81%9F%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC"><i class="fa fa-link"></i></a>5.2.3.4 ネストした交差検証</h4>

<ul>
<li>データセットを一度だけ評価用に分割すると、その分割に評価が依存してしまう</li>
<li>最終的なスコアも交差検証によって求める</li>
<li>未来予測には使えない</li>
<li>あるモデルのあるデータセットに対する性能評価に有用</li>
</ul>

<h4>
<span id="5235-交差検証とグリッドサーチの並列化" class="fragment"></span><a href="#5235-%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%A8%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%B5%E3%83%BC%E3%83%81%E3%81%AE%E4%B8%A6%E5%88%97%E5%8C%96"><i class="fa fa-link"></i></a>5.2.3.5 交差検証とグリッドサーチの並列化</h4>

<ul>
<li>グリッドサーチは単純並列</li>
<li>並列化できる</li>
<li>scikit-learnでは複数マシンの並列化は実装されていない

<ul>
<li>IPythonの並列化フレームワークで可能</li>
</ul>
</li>
<li>spark-sklearnではSparkクラスタでグリッドサーチを実行できる</li>
</ul>

<h1>
<span id="所感" class="fragment"></span><a href="#%E6%89%80%E6%84%9F"><i class="fa fa-link"></i></a>所感</h1>

<ul>
<li>特にグリッドサーチ、これが学生時代にあれば…という感じ</li>
</ul>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
</pre></div></div>
</div><div class="sns-buttons"><ul><li><div class="twitter-button"><a class="twitter-share-button" data-related="nownabe" data-via="nownabe" href="https://twitter.com/share">Tweet</a></div></li><li><div class="fb-like" data-action="like" data-layout="button_count" data-share="true" data-show-faces="false" data-size="small"></div></li><li><a class="tumblr-share-button" href="https://www.tumblr.com/share"></a></li><li><a class="hatena-bookmark-button" data-hatena-bookmark-lang="ja" data-hatena-bookmark-layout="standard-balloon" href="http://b.hatena.ne.jp/entry/" title="このエントリーをはてなブックマークに追加"><img alt="このエントリーをはてなブックマークに追加" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20"></a></li><li><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></li></ul></div></article></div></div><div id="footer-container"><footer class="container"><p class="copyright">Copyright &copy; 2016<img alt="now" src="/images/nownabe.svg">nownabe All Right Reserved.</p></footer><aside class="container" id="information"><ul id="links"><li><a href="https://nownabe.github.io"><img alt="nownabe.github.io" src="/images/nownabe.svg"></a></li><li><a href="https://github.com/nownabe"><img alt="github.com/nownabe" src="/images/github.svg"></a></li><li><a href="https://qiita.com/nownabe"><img alt="qiita.com/nownabe" src="/images/qiita.svg"></a></li><li><a href="https://twitter.com/nownabe"><img alt="twitter.com/nownabe" src="/images/twitter.svg"></a></li><li><a href="https://www.facebook.com/nownabe"><img alt="www.facebook.com/nownabe" src="/images/facebook.png"></a></li></ul></aside><div class="container"><p>今が最高</p></div></div><div id="fb-root"></div></div><script>// Twitter
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><script>// Facebook
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.7&appId=1775541316016693";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script><script>// Pocket
!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js"></script></body></html>