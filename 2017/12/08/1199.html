<!DOCTYPE html><html><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><meta charset="utf-8"><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta content="width=device-width, initial-scale=1" name="viewport"><title>nownab.log | Pythonではじめる機械学習  4回目</title><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" /><link href="/styles/ress.min.css" rel="stylesheet"><link href="/styles/font-awesome.min.css" rel="stylesheet"><link href="/styles/index.css" rel="stylesheet"><link href="/styles/highlight.css" rel="stylesheet"><link href="/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.ico"><meta content="nownab.log" property="og:site_name"><meta content="article" property="og:type"><meta content="summary" property="twitter:card"><meta content="@nownabe" property="twitter:site"><meta content="@nownabe" property="twitter:creator"><meta content="https://blog.nownabe.com/images/nownabe.png" property="twitter:image"><meta content="1775541316016693" property="fb:app_id"><meta content="Pythonではじめる機械学習  4回目" property="og:title"><meta content=" nownab.log | Pythonではじめる機械学習 3回目     週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/machine-learning-study: 機械学習勉強会   この記事は資料作りの下書き的扱い。     3章 教師なし学習と前処理     3.5 クラスタリング     3.5.2 凝集型クラスタリング       凝集型ク...     " property="og:description"><meta content="https://blog.nownabe.com/images/nownabe.png" property="og:image"><meta content="https://blog.nownabe.com/2017/12/08/1199.html" property="og:url"><meta content=" nownab.log | Pythonではじめる機械学習 3回目     週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。   また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。   Wondershake/machine-learning-study: 機械学習勉強会   この記事は資料作りの下書き的扱い。     3章 教師なし学習と前処理     3.5 クラスタリング     3.5.2 凝集型クラスタリング       凝集型ク...     " property="twitter:description"><meta content="Pythonではじめる機械学習  4回目" property="twitter:title"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37580164-4', 'auto');
ga('send', 'pageview');</script></head><body><div id="site-container"><div id="header-container"><header class="container" role="banner"><h1><a href="/"><img alt="now" src="/images/nownabe.svg">nownab.log</a></h1><p>nownab.log is the life log of nownabe</p></header></div><div id="content-container"><div class="container" id="content" role="main"><article><div class="title"><h1><a href="/2017/12/08/1199.html">Pythonではじめる機械学習  4回目</a></h1><span class="date">Posted on&nbsp;Nov 27, 2017</span></div><div class="body"><p><a href="https://blog.nownabe.com/2017/11/19/1185.html">nownab.log | Pythonではじめる機械学習 3回目</a></p>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=nownabe0c-22&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=4873117984&amp;linkId=05656b0761603e4e9f88423f102e42c6"></iframe>

<p>週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。</p>

<p>また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。<br>
<a href="https://github.com/Wondershake/machine-learning-study" rel="nofollow noopener" target="_blank">Wondershake/machine-learning-study: 機械学習勉強会</a></p>

<p>この記事は資料作りの下書き的扱い。</p>

<h1>
<span id="3章-教師なし学習と前処理" class="fragment"></span><a href="#3%E7%AB%A0-%E6%95%99%E5%B8%AB%E3%81%AA%E3%81%97%E5%AD%A6%E7%BF%92%E3%81%A8%E5%89%8D%E5%87%A6%E7%90%86"><i class="fa fa-link"></i></a>3章 教師なし学習と前処理</h1>

<h2>
<span id="35-クラスタリング" class="fragment"></span><a href="#35-%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0"><i class="fa fa-link"></i></a>3.5 クラスタリング</h2>

<h3>
<span id="352-凝集型クラスタリング" class="fragment"></span><a href="#352-%E5%87%9D%E9%9B%86%E5%9E%8B%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0"><i class="fa fa-link"></i></a>3.5.2 凝集型クラスタリング</h3>

<ul>
<li>
<strong>凝集型クラスタリング (agglomerative clustering)</strong>

<ul>
<li>個々のデータポイントを1つのクラスタとして開始し、類似するクラスタを併合していくようなクラスタリングのアルゴリズム</li>
</ul>
</li>
<li>様々な類似度がある

<ul>
<li>ward / average / complete</li>
<li>だいたいward使っとけばOK</li>
</ul>
</li>
<li>新しいデータに対する予測はできない</li>
</ul>

<h4>
<span id="3521-階層型クラスタリングとデンドログラム" class="fragment"></span><a href="#3521-%E9%9A%8E%E5%B1%A4%E5%9E%8B%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%A8%E3%83%87%E3%83%B3%E3%83%89%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0"><i class="fa fa-link"></i></a>3.5.2.1 階層型クラスタリングとデンドログラム</h4>

<ul>
<li>凝集型クラスタリングは<strong>階層型クラスタリング (hierarchical clustering)</strong>を行う</li>
<li>
<strong>デンドログラム (dendrogram)</strong>で可視化できる</li>
</ul>

<h3>
<span id="353-dbscan" class="fragment"></span><a href="#353-dbscan"><i class="fa fa-link"></i></a>3.5.3 DBSCAN</h3>

<ul>
<li>
<strong>DBSCAN (dencity-based spatial clustering of applications with noise)</strong>

<ul>
<li>密度に基づくノイズあり空間クラスタリング</li>
</ul>
</li>
<li>クラスタ数を自動決定する</li>
<li>k-meansより遅い</li>
<li>比較的大きなデータセットにも適用できる</li>
<li>どのクラスタにも属さないデータポイントをノイズとする

<ul>
<li>外れ値検出に使える</li>
</ul>
</li>
<li>近さの閾値とクラスタを構成する最小のデータ数がパラメータ</li>
</ul>

<h3>
<span id="354-クラスタリングアルゴリズムの比較と評価" class="fragment"></span><a href="#354-%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E6%AF%94%E8%BC%83%E3%81%A8%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3.5.4 クラスタリングアルゴリズムの比較と評価</h3>

<h4>
<span id="3541-正解データを用いたクラスタリングの評価" class="fragment"></span><a href="#3541-%E6%AD%A3%E8%A7%A3%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3.5.4.1 正解データを用いたクラスタリングの評価</h4>

<ul>
<li>重要な指標

<ul>
<li><strong>調整ランド指数 (adjusted rand index: ARI)</strong></li>
<li><strong>正規化相互情報量 (normalized mutual information: NMI)</strong></li>
</ul>
</li>
<li>Accuracyは評価に適さない</li>
</ul>

<h4>
<span id="3542-正解データを用いないクラスタリングの評価" class="fragment"></span><a href="#3542-%E6%AD%A3%E8%A7%A3%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E7%94%A8%E3%81%84%E3%81%AA%E3%81%84%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3.5.4.2 正解データを用いないクラスタリングの評価</h4>

<ul>
<li>クラスタリングタスクでは正解データがない場合が多い</li>
<li>
<strong>シルエット係数 (silhouette coefficient)</strong>

<ul>
<li>正解データを必要としないクラスタリングの評価指標</li>
<li>実際にはうまく評価できない</li>
</ul>
</li>
<li>頑健性を用いた評価指標がある</li>
</ul>

<h4>
<span id="3543-顔画像データセットを用いたアルゴリズムの比較" class="fragment"></span><a href="#3543-%E9%A1%94%E7%94%BB%E5%83%8F%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E6%AF%94%E8%BC%83"><i class="fa fa-link"></i></a>3.5.4.3 顔画像データセットを用いたアルゴリズムの比較</h4>

<h3>
<span id="355-クラスタリング手法のまとめ" class="fragment"></span><a href="#355-%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E6%89%8B%E6%B3%95%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81"><i class="fa fa-link"></i></a>3.5.5 クラスタリング手法のまとめ</h3>

<ul>
<li>クラスタリングは評価も含めて定性的</li>
<li>データの探索的な解析に最も役立つ</li>
<li>k-means

<ul>
<li>クラスタセンタでクラスタの特徴を表すことが可能</li>
</ul>
</li>
<li>凝集型クラスタリング

<ul>
<li>階層的なクラスタリングが可能</li>
</ul>
</li>
<li>DBSCAN

<ul>
<li>クラスタ数を自動決定</li>
<li>ノイズ検出が可能</li>
</ul>
</li>
</ul>

<h1>
<span id="4章-データの表現と特徴量エンジニアリング" class="fragment"></span><a href="#4%E7%AB%A0-%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%A1%A8%E7%8F%BE%E3%81%A8%E7%89%B9%E5%BE%B4%E9%87%8F%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0"><i class="fa fa-link"></i></a>4章 データの表現と特徴量エンジニアリング</h1>

<ul>
<li>
<strong>連続値特徴量 (continuous feature)</strong>だけでなく、<strong>カテゴリ特徴量 (categorical feature)</strong>も扱う必要がある</li>
<li>
<strong>特徴量エンジニアリング (feature engineering)</strong>

<ul>
<li>最良のデータ表現を模索すること</li>
</ul>
</li>
</ul>

<h2>
<span id="41-カテゴリ変数" class="fragment"></span><a href="#41-%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E5%A4%89%E6%95%B0"><i class="fa fa-link"></i></a>4.1 カテゴリ変数</h2>

<ul>
<li>性別や学歴などはそのままではロジスティック回帰などのアルゴリズムで学習できない</li>
</ul>

<h3>
<span id="411-ワンホットエンコーディング-ダミー変数" class="fragment"></span><a href="#411-%E3%83%AF%E3%83%B3%E3%83%9B%E3%83%83%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0-%E3%83%80%E3%83%9F%E3%83%BC%E5%A4%89%E6%95%B0"><i class="fa fa-link"></i></a>4.1.1 ワンホットエンコーディング (ダミー変数)</h3>

<ul>
<li>
<strong>ワンホットエンコーディング (one-hot-encoding)</strong>

<ul>
<li>カテゴリ変数を1つ以上の、0か1を取る新しい特徴量で置き換える方法</li>
<li>性別の場合は次のような2つの特徴量として表す

<ul>
<li>男の場合は1、それ以外は0</li>
<li>女の場合は1、それ以外は0</li>
</ul>
</li>
</ul>
</li>
<li>pandasを使うと簡単</li>
</ul>

<h4>
<span id="4111-文字列で表されているカテゴリデータのチェック" class="fragment"></span><a href="#4111-%E6%96%87%E5%AD%97%E5%88%97%E3%81%A7%E8%A1%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF"><i class="fa fa-link"></i></a>4.1.1.1 文字列で表されているカテゴリデータのチェック</h4>

<ul>
<li>表記ゆれなどを前処理する必要がある</li>
<li>Seriesクラスの<code>value_counts</code>メソッドでチェックできる</li>
<li>
<code>get_dummies</code>関数でワンホットエンコーディングできる</li>
</ul>

<h3>
<span id="412-数値でエンコードされているカテゴリ" class="fragment"></span><a href="#412-%E6%95%B0%E5%80%A4%E3%81%A7%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%89%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA"><i class="fa fa-link"></i></a>4.1.2 数値でエンコードされているカテゴリ</h3>

<ul>
<li>そのままではpandasにカテゴリ変数として解釈されない

<ul>
<li>scikit-learnのOneHotEncoderを使う</li>
<li>DataFrameの列名を文字列に変換する</li>
</ul>
</li>
</ul>

<h2>
<span id="42-ビニング離散化線形モデル決定木" class="fragment"></span><a href="#42-%E3%83%93%E3%83%8B%E3%83%B3%E3%82%B0%E9%9B%A2%E6%95%A3%E5%8C%96%E7%B7%9A%E5%BD%A2%E3%83%A2%E3%83%87%E3%83%AB%E6%B1%BA%E5%AE%9A%E6%9C%A8"><i class="fa fa-link"></i></a>4.2 ビニング、離散化、線形モデル、決定木</h2>

<ul>
<li>
<strong>ビニング (binning)</strong>

<ul>
<li>
<strong>離散化 (discretization)</strong>とも</li>
<li>線形モデルを連続データに対してより強力にする</li>
<li>データのレンジを複数のビンとして分割し、そのデータがどのビンに入るかをワンホットエンコーディングで表す</li>
<li>それぞれのビン内ではすべて同じ予測をする</li>
<li>データが大きくて高次元な場合で、線形モデルを使って非線形なモデルを構築したいときに有効</li>
</ul>
</li>
</ul>

<h2>
<span id="43-交互作用と多項式" class="fragment"></span><a href="#43-%E4%BA%A4%E4%BA%92%E4%BD%9C%E7%94%A8%E3%81%A8%E5%A4%9A%E9%A0%85%E5%BC%8F"><i class="fa fa-link"></i></a>4.3 交互作用と多項式</h2>

<ul>
<li>
<strong>交互作用特徴量 (interaction feature)</strong>

<ul>
<li><code>x_product = np.hstack([x_binned, x * x_binned])</code></li>
</ul>
</li>
<li>
<strong>多項式特徴量 (polynomial feature)</strong>

<ul>
<li>
<code>x ** 2</code>や<code>x ** 3</code>のような特徴量</li>
<li>
<code>PolynomialFeatures</code>で実現可能</li>
</ul>
</li>
</ul>

<h2>
<span id="44-単変量非線形変換" class="fragment"></span><a href="#44-%E5%8D%98%E5%A4%89%E9%87%8F%E9%9D%9E%E7%B7%9A%E5%BD%A2%E5%A4%89%E6%8F%9B"><i class="fa fa-link"></i></a>4.4 単変量非線形変換</h2>

<ul>
<li>
<code>x ** 2</code>や<code>x ** 3</code>のような特徴量は線形回帰モデルで有用</li>
<li>
<strong>単変量非線形変換</strong>

<ul>
<li>log, exp, sinなどを使ってデータを変換する</li>
<li>元々非線形なデータを線形モデルで扱えるようにする</li>
<li>ニューラルネットワークモデル等にも有効</li>
</ul>
</li>
</ul>

<h1>
<span id="所感" class="fragment"></span><a href="#%E6%89%80%E6%84%9F"><i class="fa fa-link"></i></a>所感</h1>

<ul>
<li>まとめるの遅くなった <img class="emoji" title=":disappointed:" alt=":disappointed:" src="/images/emoji/unicode/1f61e.svg" height="20" width="20" align="absmiddle"> </li>
</ul>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
</pre></div></div>
</div><div class="sns-buttons"><ul><li><div class="twitter-button"><a class="twitter-share-button" data-related="nownabe" data-via="nownabe" href="https://twitter.com/share">Tweet</a></div></li><li><div class="fb-like" data-action="like" data-layout="button_count" data-share="true" data-show-faces="false" data-size="small"></div></li><li><a class="tumblr-share-button" href="https://www.tumblr.com/share"></a></li><li><a class="hatena-bookmark-button" data-hatena-bookmark-lang="ja" data-hatena-bookmark-layout="standard-balloon" href="http://b.hatena.ne.jp/entry/" title="このエントリーをはてなブックマークに追加"><img alt="このエントリーをはてなブックマークに追加" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20"></a></li><li><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></li></ul></div></article></div></div><div id="footer-container"><footer class="container"><p class="copyright">Copyright &copy; 2016<img alt="now" src="/images/nownabe.svg">nownabe All Right Reserved.</p></footer><aside class="container" id="information"><ul id="links"><li><a href="https://nownabe.github.io"><img alt="nownabe.github.io" src="/images/nownabe.svg"></a></li><li><a href="https://github.com/nownabe"><img alt="github.com/nownabe" src="/images/github.svg"></a></li><li><a href="https://qiita.com/nownabe"><img alt="qiita.com/nownabe" src="/images/qiita.svg"></a></li><li><a href="https://twitter.com/nownabe"><img alt="twitter.com/nownabe" src="/images/twitter.svg"></a></li><li><a href="https://www.facebook.com/nownabe"><img alt="www.facebook.com/nownabe" src="/images/facebook.png"></a></li></ul></aside><div class="container"><p>今が最高</p></div></div><div id="fb-root"></div></div><script>// Twitter
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><script>// Facebook
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.7&appId=1775541316016693";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script><script>// Pocket
!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js"></script></body></html>