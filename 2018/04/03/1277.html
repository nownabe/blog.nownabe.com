<!DOCTYPE html><html><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><meta charset="utf-8"><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta content="width=device-width, initial-scale=1" name="viewport"><title>nownab.log | 言語処理のための機械学習入門 第7回</title><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" /><link href="/styles/ress.min.css" rel="stylesheet"><link href="/styles/font-awesome.min.css" rel="stylesheet"><link href="/styles/index.css" rel="stylesheet"><link href="/styles/highlight.css" rel="stylesheet"><link href="/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.ico"><meta content="nownab.log" property="og:site_name"><meta content="article" property="og:type"><meta content="summary" property="twitter:card"><meta content="@nownabe" property="twitter:site"><meta content="@nownabe" property="twitter:creator"><meta content="https://blog.nownabe.com/images/nownabe.png" property="twitter:image"><meta content="1775541316016693" property="fb:app_id"><meta content="言語処理のための機械学習入門 第7回" property="og:title"><meta content=" nownab.log | 言語処理のための機械学習入門 第4回     概要   機械学習勉強会で輪読してる 言語処理のための機械学習入門 の学習メモです。  勉強会用の資料があるのでこちらでは資料に載らなかったメモ等を。     範囲     2. 文書および単語の数学的表現    2.1 タイプ, トークン   2.2 nグラム   2.3 文書, 文のベクトル表現   2.4 文書に対する前処理とデータスパースネス問題   2.5 単語のベクトル表現   2.6 文書や単語の確率分布による表現   2.7 この章のまとめ   章末問...       " property="og:description"><meta content="https://blog.nownabe.com/images/nownabe.png" property="og:image"><meta content="https://blog.nownabe.com/2018/04/03/1277.html" property="og:url"><meta content=" nownab.log | 言語処理のための機械学習入門 第4回     概要   機械学習勉強会で輪読してる 言語処理のための機械学習入門 の学習メモです。  勉強会用の資料があるのでこちらでは資料に載らなかったメモ等を。     範囲     2. 文書および単語の数学的表現    2.1 タイプ, トークン   2.2 nグラム   2.3 文書, 文のベクトル表現   2.4 文書に対する前処理とデータスパースネス問題   2.5 単語のベクトル表現   2.6 文書や単語の確率分布による表現   2.7 この章のまとめ   章末問...       " property="twitter:description"><meta content="言語処理のための機械学習入門 第7回" property="twitter:title"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37580164-4', 'auto');
ga('send', 'pageview');</script></head><body><div id="site-container"><div id="header-container"><header class="container" role="banner"><h1><a href="/"><img alt="now" src="/images/nownabe.svg">nownab.log</a></h1><p>nownab.log is the life log of nownabe</p></header></div><div id="content-container"><div class="container" id="content" role="main"><article><div class="title"><h1><a href="/2018/04/03/1277.html">言語処理のための機械学習入門 第7回</a></h1><span class="date">Posted on&nbsp;Apr 03, 2018</span></div><div class="body"><p><a href="https://blog.nownabe.com/2018/03/14/1271.html">nownab.log | 言語処理のための機械学習入門 第4回</a></p>

<h1>
<span id="概要" class="fragment"></span><a href="#%E6%A6%82%E8%A6%81"><i class="fa fa-link"></i></a>概要</h1>

<p>機械学習勉強会で輪読してる<a href="http://amzn.to/2BFQSee" rel="nofollow noopener" target="_blank">言語処理のための機械学習入門</a>の学習メモです。<br>
勉強会用の資料があるのでこちらでは資料に載らなかったメモ等を。</p>

<h1>
<span id="範囲" class="fragment"></span><a href="#%E7%AF%84%E5%9B%B2"><i class="fa fa-link"></i></a>範囲</h1>

<ul>
<li>2. 文書および単語の数学的表現

<ul>
<li>2.1 タイプ, トークン</li>
<li>2.2 nグラム</li>
<li>2.3 文書, 文のベクトル表現</li>
<li>2.4 文書に対する前処理とデータスパースネス問題</li>
<li>2.5 単語のベクトル表現</li>
<li>2.6 文書や単語の確率分布による表現</li>
<li>2.7 この章のまとめ</li>
<li>章末問題</li>
</ul>
</li>
</ul>

<h1>
<span id="資料" class="fragment"></span><a href="#%E8%B3%87%E6%96%99"><i class="fa fa-link"></i></a>資料</h1>

<h1>
<span id="2-文書および単語の数学的表現" class="fragment"></span><a href="#2-%E6%96%87%E6%9B%B8%E3%81%8A%E3%82%88%E3%81%B3%E5%8D%98%E8%AA%9E%E3%81%AE%E6%95%B0%E5%AD%A6%E7%9A%84%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2 文書および単語の数学的表現</h1>

<h2>
<span id="21-タイプ-トークン" class="fragment"></span><a href="#21-%E3%82%BF%E3%82%A4%E3%83%97-%E3%83%88%E3%83%BC%E3%82%AF%E3%83%B3"><i class="fa fa-link"></i></a>2.1 タイプ, トークン</h2>

<p>自分でなにかするときはもちろん意識してるけど会話するときは「単語」としか言ってなかったので, 会話の中で単語トークンと単語タイプを使い分けるのやったほうがよさそう.</p>

<h2>
<span id="22-nグラム" class="fragment"></span><a href="#22-n%E3%82%B0%E3%83%A9%E3%83%A0"><i class="fa fa-link"></i></a>2.2 nグラム</h2>

<h3>
<span id="221-単語nグラム" class="fragment"></span><a href="#221-%E5%8D%98%E8%AA%9En%E3%82%B0%E3%83%A9%E3%83%A0"><i class="fa fa-link"></i></a>2.2.1 単語nグラム</h3>

<h3>
<span id="222-文字nグラム" class="fragment"></span><a href="#222-%E6%96%87%E5%AD%97n%E3%82%B0%E3%83%A9%E3%83%A0"><i class="fa fa-link"></i></a>2.2.2 文字nグラム</h3>

<h2>
<span id="23-文書-文のベクトル表現" class="fragment"></span><a href="#23-%E6%96%87%E6%9B%B8-%E6%96%87%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.3 文書, 文のベクトル表現</h2>

<h3>
<span id="231-文書のベクトル表現" class="fragment"></span><a href="#231-%E6%96%87%E6%9B%B8%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.3.1 文書のベクトル表現</h3>

<p>頻度を素性値に使うものを頻度ベクトル, 出現したかどうかのみ気にするのを二値ベクトル. これもあんま使い分けしてなかったので気をつけよう.</p>

<h3>
<span id="232-文のベクトル表現" class="fragment"></span><a href="#232-%E6%96%87%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.3.2 文のベクトル表現</h3>

<h2>
<span id="24-文書に対する前処理とデータスパースネス問題" class="fragment"></span><a href="#24-%E6%96%87%E6%9B%B8%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8B%E5%89%8D%E5%87%A6%E7%90%86%E3%81%A8%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B9%E3%83%91%E3%83%BC%E3%82%B9%E3%83%8D%E3%82%B9%E5%95%8F%E9%A1%8C"><i class="fa fa-link"></i></a>2.4 文書に対する前処理とデータスパースネス問題</h2>

<h3>
<span id="241-文書に対する前処理" class="fragment"></span><a href="#241-%E6%96%87%E6%9B%B8%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8B%E5%89%8D%E5%87%A6%E7%90%86"><i class="fa fa-link"></i></a>2.4.1 文書に対する前処理</h3>

<h3>
<span id="242-日本語の前処理" class="fragment"></span><a href="#242-%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86"><i class="fa fa-link"></i></a>2.4.2 日本語の前処理</h3>

<h3>
<span id="243データスパースネス問題" class="fragment"></span><a href="#243%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B9%E3%83%91%E3%83%BC%E3%82%B9%E3%83%8D%E3%82%B9%E5%95%8F%E9%A1%8C"><i class="fa fa-link"></i></a>2.4.3.データスパースネス問題</h3>

<h2>
<span id="25-単語のベクトル表現" class="fragment"></span><a href="#25-%E5%8D%98%E8%AA%9E%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.5 単語のベクトル表現</h2>

<h3>
<span id="251-単語トークンの文脈ベクトル表現" class="fragment"></span><a href="#251-%E5%8D%98%E8%AA%9E%E3%83%88%E3%83%BC%E3%82%AF%E3%83%B3%E3%81%AE%E6%96%87%E8%84%88%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.5.1 単語トークンの文脈ベクトル表現</h3>

<h3>
<span id="252-単語タイプの文脈ベクトル表現" class="fragment"></span><a href="#252-%E5%8D%98%E8%AA%9E%E3%82%BF%E3%82%A4%E3%83%97%E3%81%AE%E6%96%87%E8%84%88%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.5.2 単語タイプの文脈ベクトル表現</h3>

<p>単純に足し合わせるだけなのかー. 正規化とか必要そう.</p>

<h2>
<span id="26-文書や単語の確率分布による表現" class="fragment"></span><a href="#26-%E6%96%87%E6%9B%B8%E3%82%84%E5%8D%98%E8%AA%9E%E3%81%AE%E7%A2%BA%E7%8E%87%E5%88%86%E5%B8%83%E3%81%AB%E3%82%88%E3%82%8B%E8%A1%A8%E7%8F%BE"><i class="fa fa-link"></i></a>2.6 文書や単語の確率分布による表現</h2>

<h2>
<span id="27-この章のまとめ" class="fragment"></span><a href="#27-%E3%81%93%E3%81%AE%E7%AB%A0%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81"><i class="fa fa-link"></i></a>2.7 この章のまとめ</h2>

<h2>
<span id="章末問題" class="fragment"></span><a href="#%E7%AB%A0%E6%9C%AB%E5%95%8F%E9%A1%8C"><i class="fa fa-link"></i></a>章末問題</h2>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
# frozen_string_literal: true

def make_ngram(n, arr)
  print "#{n}-gram: "
  vector = Hash.new { |h, k| h[k] = 0 }
  arr.each_cons(n).each_with_object(vector) { |c, v| v[c.join] += 1 }.sort_by { |a| a[0] }
end

def print_ngram(ngram)
  puts "[" + ngram.map { |e| e.join(":") }.join(", ") + "]"
end

puts "======== 1 ========"

word = "tattarrattat"

print_ngram(make_ngram(1, word.chars))
print_ngram(make_ngram(2, word.chars))
print_ngram(make_ngram(3, word.chars))

puts
puts "======== 2 ========"

sentence = "A cat sat on the mat."
stop_words = %w[a the on in of]

dic = { "sat" =&gt; "sit" }

doc = sentence.split(" ")
doc.map! { |w| w.tr(".", "") }
doc.map(&amp;:downcase)
doc.map! { |w| dic.key?(w) ? dic[w] : w }
doc.delete_if { |w| stop_words.include?(w) }
print_ngram(make_ngram(1, doc))

puts
puts "======== 3 ========"

sentence = "I had a supercalifragilisticexpialidocious time with friends."
puts "[-2=had:1, -1=a:1, +1=time:1, +2=with:1]"
</pre></div></div>

<p>3番… <img class="emoji" title=":innocent:" alt=":innocent:" src="/images/emoji/unicode/1f607.svg" height="20" width="20" align="absmiddle"></p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
======== 1 ========
1-gram: [a:4, r:2, t:6]
2-gram: [ar:1, at:3, ra:1, rr:1, ta:3, tt:2]
3-gram: [arr:1, att:2, rat:1, rra:1, tar:1, tat:2, tta:2]

======== 2 ========
1-gram: [A:1, cat:1, mat:1, sit:1]

======== 3 ========
[-2=had:1, -1=a:1, +1=time:1, +2=with:1]
</pre></div></div>

<h1>
<span id="所感" class="fragment"></span><a href="#%E6%89%80%E6%84%9F"><i class="fa fa-link"></i></a>所感</h1>

<p>Word2Vecとかも詳しく勉強してみたいなー.</p>

<h1>
<span id="言語処理のための機械学習入門" class="fragment"></span><a href="#%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%85%A5%E9%96%80"><i class="fa fa-link"></i></a>言語処理のための機械学習入門</h1>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=nownabe0c-22&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=4339027510&amp;linkId=1c6291b86381f20d113796257356ef1b"></iframe>

<h1>
<span id="機械学習勉強会について" class="fragment"></span><a href="#%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%8B%89%E5%BC%B7%E4%BC%9A%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><i class="fa fa-link"></i></a>機械学習勉強会について</h1>

<p>社内で毎週開催している。本書は輪読形式でまわしているが、題材によって形式は柔軟に変えている。<br>
毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。</p>

<p>また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。<br>
<a href="https://github.com/Wondershake/machine-learning-study" rel="nofollow noopener" target="_blank">Wondershake/machine-learning-study: 機械学習勉強会</a></p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>
</pre></div></div>
</div><div class="sns-buttons"><ul><li><div class="twitter-button"><a class="twitter-share-button" data-related="nownabe" data-via="nownabe" href="https://twitter.com/share">Tweet</a></div></li><li><div class="fb-like" data-action="like" data-layout="button_count" data-share="true" data-show-faces="false" data-size="small"></div></li><li><a class="tumblr-share-button" href="https://www.tumblr.com/share"></a></li><li><a class="hatena-bookmark-button" data-hatena-bookmark-lang="ja" data-hatena-bookmark-layout="standard-balloon" href="http://b.hatena.ne.jp/entry/" title="このエントリーをはてなブックマークに追加"><img alt="このエントリーをはてなブックマークに追加" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20"></a></li><li><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></li></ul></div></article></div></div><div id="footer-container"><footer class="container"><p class="copyright">Copyright &copy; 2016<img alt="now" src="/images/nownabe.svg">nownabe All Right Reserved.</p></footer><aside class="container" id="information"><ul id="links"><li><a href="https://nownabe.github.io"><img alt="nownabe.github.io" src="/images/nownabe.svg"></a></li><li><a href="https://github.com/nownabe"><img alt="github.com/nownabe" src="/images/github.svg"></a></li><li><a href="https://qiita.com/nownabe"><img alt="qiita.com/nownabe" src="/images/qiita.svg"></a></li><li><a href="https://twitter.com/nownabe"><img alt="twitter.com/nownabe" src="/images/twitter.svg"></a></li><li><a href="https://www.facebook.com/nownabe"><img alt="www.facebook.com/nownabe" src="/images/facebook.png"></a></li></ul></aside><div class="container"><p>今が最高</p></div></div><div id="fb-root"></div></div><script>// Twitter
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><script>// Facebook
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.7&appId=1775541316016693";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script><script>// Pocket
!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js"></script></body></html>