---
date: 2017-12-04T17:37:06+0900
lastmod: 2017-12-08T16:50:27+0900
tags: ["機械学習勉強会", "統計学入門"]
draft: false
isCJKLanguage: true

title: "Pythonではじめる機械学習  6回目"
category: Log

created_at: 2017-12-04 17:37:06 +0900
updated_at: 2017-12-08 16:50:27 +0900
number: 1206
---

[nownab.log | Pythonではじめる機械学習 5回目](https://blog.nownabe.com/2017/12/08/1200.html)

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=nownabe0c-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=4873117984&linkId=05656b0761603e4e9f88423f102e42c6"></iframe>

週一でやっていて、毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。

また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。
[Wondershake/machine-learning-study: 機械学習勉強会](https://github.com/Wondershake/machine-learning-study)

この記事は資料作りの下書き的扱い。

# 5章 モデルの評価と改良
## 5.3 評価基準とスコア
### 5.3.1 最終的な目標を見失わないこと
### 5.3.2 2クラス分類における基準
#### 5.3.2.1 エラーの種類
* **偽陽性 (false positive)**: FP
    * 陽性でないのに陽性と判断してしまう間違い
    * **タイプIエラー**
* **偽陰性 (false negative)**: FN
    * 陰性でないのに陰性と判断してしまう間違い
    * **タイプIIエラー**

#### 5.3.2.2 偏ったデータセット
* 偏ったデータセットの場合「精度」は評価基準として適さない
    * 例えば99%が陰性のデータに対してすべて陰性と予測すれば99%の精度が得られる

#### 5.3.2.3 混同行列
* **真陽性 (true positive)**: TP
* **真陰性 (true negative)**: TN
* **混同行列 (confusion matrix)**
    * 真陽性、真陰性、偽陽性、偽陰性を表にまとめたもの
* $精度 = \displaystyle \frac{TP + TN}{TP + TN + FP + FN}$
* $適合率 = \displaystyle \frac{TP}{TP + FP}$
* $再現率 = \displaystyle \frac{TP}{TP + FN}$
* $F値 = \displaystyle 2 \times \frac{適合率 \times 再現率}{適合率 + 再現率}$

#### 5.3.2.4 不確実性を考慮に入れる
* 予測の閾値を調整することで適合率と再現率のトレードオフの調整が可能
* 調整にテストデータは使わないようにする
* `predict_proba`、`decision_function`を使う

#### 5.2.3.5 適合率-再現率カーブとROCカーブ
* **適合率-再現率カーブ (precision-recall curve)**
    * 予測の閾値を変化させ、適合率と再現率をプロットしたもの
    * 右上にいくほど良い
* **平均適合率 (average precision)**
    * 適合率-再現率カーブを積分したもの

#### 5.2.3.6 受信者動作特性(ROC)とAUC
* **受信者動作特性カーブ (receiver operating characteristics curve: ROCカーブ)**
    * 予測の閾値を変化させ、真陽性率(再現率)と偽陽性率をプロットしたもの
    * 左上にいくほど良い
* **AUC (area under the curve)**
    * ROCカーブの下側を積分した値
    * 偏ったデータを評価するときはAUCが良い

### 5.3.3 多クラス分類の基準
* 2値分類の基準から導出される
* F値
    * マクロ平均: クラスごとのF値を平均する
    * マイクロ平均: 全クラスのFP, FN, TPの総数を計算して、それらからF値を計算する
    * 重み付き平均: クラスごとのデータ数で重みを付けて平均する

### 5.3.4 回帰の基準
* 今までも使ってきた$R^2$が最も良い

### 5.3.5 評価基準を用いたモデル選択
* scikit-learnでは簡単に交差検証やグリッドサーチのスコアリングにAUCなどが使える

## 5.4 まとめと展望
* 見落としがちなこと
    * 交差検証は評価方法。モデルやパラメータ選択には使えない
    * テストデータを使ってモデルやパラメータ選択してはダメ
    * モデル選択やモデル評価における、評価基準、スコア関数の重要性

# 6章 アルゴリズムチェーンとパイプライン
* 機械学習ではデータの表現は非常に重要
* 機械学習アプリケーションでは様々な処理と複数の機械学習アルゴリズムを連鎖的に実行する必要がある

## 6.1 前処理を行う際のパラメータ選択
* 交差検証の前に前処理をしてしまうと、間違った前処理になってしまう
* scikit-learnではPipelineクラスで複数の処理をまとめることで解決できる

## 6.2 パイプラインの構築
## 6.3 パイプラインを用いたグリッドサーチ
* パイプラインのパラメータグリッドを指定するときは`__`でパイプライン名とパラメータ名をつなげる

## 6.4 汎用パイプラインインターフェイス
* Pipelineは任意の個数のEstimatorを連結できる
* 最後以外のステップには`fit`メソッドと`transform`メソッドが実装されている必要がある
* 最後のステップは`fit`メソッドが実装されている必要がある

### 6.4.1 make_pipelineによる簡便なパイプライン生成
* `make_pipeline`関数を使うとステップ名を自動生成する

### 6.4.2 ステップ属性へのアクセス
* `named_step`属性で各ステップにアクセスできる

### 6.4.3 GridSearchCV内のパイプラインの属性へのアクセス
* 通常通り`best_estimator_`でパイプラインにアクセスできる

## 6.5 前処理ステップとモデルパラメータに対するグリッドサーチ
* パイプラインを使うことで、前処理のパラメータとモデルのパラメータを同時にグリッドサーチで探索できる

## 6.6 グリッドサーチによるモデルの選択
* GirdSearchCVとPipelineを組み合わせると、さらに柔軟な探索も可能
* 各ステップのモデルも探索可能

## 6.7 まとめと展望
* Pipelineで複数の処理を適切にまとめることは非常に重要

# 所感
* 特にグリッドサーチ、これが学生時代にあれば…という感じ

```math
```
