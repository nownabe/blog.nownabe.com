---
date: 2017-10-24T19:29:04+0900
lastmod: 2017-10-25T20:38:54+0900
tags: ["機械学習勉強会", "統計学入門"]
draft: false
isCJKLanguage: true

title: "統計学入門  第12章 仮説検定"
category: Log

created_at: 2017-10-24 19:29:04 +0900
updated_at: 2017-10-25 20:38:54 +0900
published: true
number: 1165
---

[nownab.log | 統計学入門 第11章 推定](https://blog.nownabe.com/2017/10/16/1142.html)

<div class="asin">
<div class="asin-image"><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/" rel="nofollow noopener" target="_blank"><img src="http://images-jp.amazon.com/images/P/4130420658.09._SL160_.jpg" alt="統計学入門 (基礎統計学Ⅰ)" title="統計学入門 (基礎統計学Ⅰ)"></a></div>
<div class="asin-detail">
<p><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/" rel="nofollow noopener" target="_blank">統計学入門 (基礎統計学Ⅰ)</a></p>
<ul>
<li>東京大学教養学部統計学教室</li>
<li>東京大学出版会</li>
</ul>
</div>

<p></p>
</div>

機械学習勉強会として今は[統計学入門](https://www.amazon.co.jp/exec/obidos/ASIN/4130420658/nownabe0c-22/)をやっている。
週一でやっていて、今週から輪読形式で進めてみることになった。

また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。
[Wondershake/ml-statistics-intro: 基礎統計学 I 統計学入門 (東京大学出版会)](https://github.com/Wondershake/ml-statistics-intro)

# 今回の内容
## 12.1 検定の考え方
* 仮説検定の目的は、母集団について仮定された命題を標本に基づいて検証すること
* 仮説からのずれに意味がある場合、**有意 (significant)**であるという
* 仮説のことを**統計的仮説 (statistical hypothesis)**又は**仮説 (hypothesis)**という
* 仮説検定: 統計的仮説の**優位性検定 (test of significance)**
* **棄却 (reject)**: その仮説に基づくと観測された標本が現れる確率が希少なとき、仮説は棄却される、という
* **有意水準 (significance level)**: どの程度の希少確率を考えるかという基準の確率。
* **採択 (accept)**: 仮説が棄却できないこと
* **帰無仮説 (null hypothesis)**: 棄却されるかされないかの判断にさらされる仮説
* **対立仮説 (alternative hypothesis)**: 帰無仮説に対立する仮説
* **第一種の誤り (error of the first kind)**
    * 帰無仮説が正しいのにそれを棄却する
* **第二種の誤り (error of the second kind)**
    * 帰無仮説が誤っているのにそれを採択する
* **検定統計量 (test statistic)**: 検定に用いる統計量
* **棄却域 (rejection region)**: 帰無仮説を棄却すべき統計量の値の集合
* **採択域 (acceptance region)**: 帰無仮説を棄却しない統計量の値の集合
* **両側検定 (two-sided test)**: **両側対立仮説 (two-sided alternative hypothesis)**のときに用いる
* **片側検定 (one-sided test)**: **片側対立仮説 (one-sided alternative hypothesis)**のときに用いる

## 12.2 正規母集団に対する仮説検定
### 12.2.1 母平均に関する検定
* 両側検定
    * 帰無仮説: $H_0:\mu=\mu_0$
    * 対立仮説: $H_1: \mu\neq\mu_0$
    * 分散が既知のとき
        * 検定統計量Zを使う
        * $Z=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}$
        * $|Z|>Z_{\frac{\alpha}{2}}$のとき帰無仮説を棄却する
        * $|Z|\leq Z_{\frac{\alpha}{2}}$のとき帰無仮説を棄却しない
    * 分散が未知のとき
        * **t検定 (Student's t-test)**
        * 検定統計量tを使う
        * $t=\frac{\bar{X}-\mu}{\frac{s}{\sqrt{n}}}$
        * $|t|>t_\frac{\alpha}{2}(n-1)$のとき帰無仮説を棄却する
        * $|t|\leq t_\frac{\alpha}{2}(n-1)$のとき帰無仮説を棄却しない
* 片側検定
    * 帰無仮説: $H_0:\mu=\mu_0$
    * 対立仮説: $H_1: \mu>\mu_0$
    * 分散が既知のとき
        * $Z>Z_\alpha$のとき帰無仮説を棄却する
        * $Z\leq Z_\alpha$のとき帰無仮説を棄却しない
    * 分散が未知のとき
        * $t>t_\alpha(n-1)$のとき帰無仮説を棄却する
        * $t\leq t_\alpha(n-1)$のとき帰無仮説を棄却しない

### 12.2.2 母分散に対する仮説検定
* **$\chi^2$検定 ($\chi^2$-test)**
    * 帰無仮説: $H_0: \sigma^2=\sigma_0^2$
    * $\chi^2=(n-1)\frac{s^2}{\sigma_0^2}$
    * 両側検定
        * 対立仮説: $H_1: \sigma^2\neq\sigma_0^2$
        * $\chi^2_{1-\frac{\alpha}{2}}(n-1)<\chi^2<\chi^2_{\frac{\alpha}{2}}(n-1)$のとき帰無仮説を棄却せず、それ以外で棄却する
    * 片側検定
        * 対立仮説: $H_1: \sigma^2<\sigma_0^2$
        * $\chi^2<\chi^2_{1-\alpha}(n-1)$のとき帰無仮説を棄却し、それ以外で棄却しない

### 12.2.3 母平均の差の検定
* **2標本検定 (two-sample test)**: 2つのグループで結果に差があるかどうかを検定する
    * 治療法の効果を調べるときなど
    * 治療等を行ったグループを**処理群 (treatment group)**という
    * 行わなかった基準となるグループを**対照群 (contrast group)**または**制御群 (control group)**という
    * 帰無仮説 $H_0: \mu_1=\mu_2$
    * 母分散が等しいとき
        * 2標本t統計量 $t=\frac{\displaystyle\bar{X}-\bar{Y}}{\displaystyle s\sqrt{\frac{1}{m}+\frac{1}{n}}}$
        * 両側検定
            * 対立仮説 $H_1: \mu_1\neq\mu_2$
            * $|t|>t_\frac{\alpha}{2}(m+n-2)$のとき帰無仮説を棄却する
        * 片側検定
            * 対立仮説 $H_1: \mu_1>\mu_2$
            * $t>t_\alpha(m+n-2)$のとき帰無仮説を棄却する
    * 母分散が等しくないとき
        * **ウェルチの検定 (Welch's test)**

### 12.2.4 母分散の比の検定
* 2つの正規母集団の母平均が等しいか否か
* 帰無仮説 $H_0:\sigma_1^2=\sigma_2^2$
* 対立仮説 $H_1:\sigma_1^2\neq\sigma_2^2$
* 統計量 $F=\frac{s_1^2}{s_2^2}$
* $F_{1-\frac{\alpha}{2}}(m-1, n-1)\leq F\leq F_\frac{\alpha}{2}(m-1, n-1)$のとき帰無仮説を棄却しない
* **F検定**

## 12.3 いろいろの$\chi^2$検定
### 12.3.1 適合度の検定
* **適合度の$\chi^2$検定 ($\chi^2$-test of goodness of fit)**
    * 仮定された理論上の確率分布に対して、標本から求められた度数が適合するか否か
    * $n$個の標本が$k$主のカテゴリ$A_1,\dots,A_k$へ分類されたとする
    * **観測度数 (Observed frequency)**: $f_1,\dots,f_k$
    * 各カテゴリの理論確率: $p_1,\dots,p_k$
    * 理論度数(または**期待度数 (Expected frequency)**): $np_1, \dots, np_k$
    * K. ピアソンの適合度基準 $\chi^2=\sum_{i=1}^{k}\frac{(f_i-np_i)^2}{np_i}$
    * 帰無仮説 $H_0: P(A_1)=p_1,\dots,P(A_k)=p_k$
    * $\chi^2>\chi_\alpha^2(k-1)$なら帰無仮説は棄却される
* $\chi^2=\sum\frac{(O-E)^2}{E}$と要約できる
    * O: Observed
    * E: Expected

### 12.3.2 分割表と独立性の検定
* **独立性の$\chi^2$検定 ($\chi^2$ test for independence)**
    * $n$個の個体に対して2つの異なる属性$A, B$を同時に測定したとする
    * $A$は$A_1,\dots,A_r$
    * $B$は$B_1,\dots,B_c$
    * **分割表**: A, Bについて度数を集計した表
    * 独立の仮説: $H_0: すべてのi,jに対しP(A_i\cap B_j)=P(A_i)P(B_j)$
    * $\chi^2=\sum_i\sum_j\frac{\displaystyle (f_{ij}-\frac{f_{i\cdot}f_{\cdot j}}{n})^2}{\displaystyle \frac{f_{i\cdot}f_{\cdot j}}{n}}=\sum_i\sum_j\frac{\displaystyle (nf_{ij}-f_{i\cdot}f_{\cdot j})^2}{\displaystyle nf_{i\cdot}f_{\cdot j}}$
    * 自由度は$(r-1)(c-1)$

## 12.4 中心極限定理を用いる検定
* 各$X_i$が独立に$B_i(1, p)$に従う
* $S_n=X_i+\dots+X_n$
* $\hat{p}=\frac{S_n}{n}$
* 検定統計量 $Z=\frac{\hat{p}-p}{\sqrt{p(1-p)/n}}$

# 練習問題
[第12章 仮説検定 · Issue #26 · Wondershake/machine-learning-study](https://github.com/Wondershake/machine-learning-study/issues/26)


# 所感
* 理解度が怪しい部門第1位の検定をちゃんと勉強できてよかった

```math
```
