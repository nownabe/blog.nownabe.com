---
date: 2017-02-23T23:50:04+0900
lastmod: 2017-08-04T18:44:54+0900
tags: ["機械学習勉強会"]
draft: false
isCJKLanguage: true

title: "機械学習勉強会 20170223"
category: Log

created_at: 2017-02-23 23:50:04 +0900
updated_at: 2017-08-04 18:44:54 +0900
published: true
number: 622
---

<div class="asin">
<div class="asin-image"><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4873117585/nownabe0c-22/" rel="nofollow noopener" target="_blank"><img src="http://images-jp.amazon.com/images/P/4873117585.09._SL160_.jpg" alt="ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装" title="ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装"></a></div>
<div class="asin-detail">
<p><a href="https://www.amazon.co.jp/exec/obidos/ASIN/4873117585/nownabe0c-22/" rel="nofollow noopener" target="_blank">ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装</a></p>
<ul>
<li>斎藤 康毅</li>
<li>オライリージャパン</li>
</ul>
</div>

<p></p>
</div>

# 今日の内容
* 3章 ニューラルネットワーク
    * 3.5 出力層の設計
    * 3.6 手書き数字認識
    * 3.7 まとめ
* 4章 ニューラルネットワークの学習
    * 4.1 データから学習する
    * 4.2 損失関数

# まとめ
* 機械学習
    * 回帰問題: 数値予測
    * 分類問題
* ニューラルネットワークによる分類は、出力層のニューロンをクラスの数だけ用意して各ニューロンの出力を確率で表現する
    * ソフトマックス関数
* 回帰問題では恒等関数を出力層の活性化関数に使う
* ニューラルネットワーク(ディープラーニング)の学習には特徴量を抽出するステップがない
    * そこ含めて勝手にやってくれる
* 

# 所感
いよいよ学習のところで、おもしろくなってきた :heart_eyes: 
