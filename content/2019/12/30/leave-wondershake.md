---
title: "Wondershakeを退職しました"
tags:
  - job
  - Wondershake
date: 2019-12-30T23:20:05+09:00
lastmod: 2019-12-30T23:20:05+09:00

draft: false
isCJKLanguage: true
---

# はじめに

いろいろとすぐ忘れてしまうので、感情を込めずに備忘録的な意味で書いてます。

年末にトイレにこもって腹痛と戦いながら書いたので、読んでいただけると報われます :poop:

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">バリ島でもらった下痢もう三日経つのにまだ治らない…</p>&mdash; ぎっくり腰太郎 (@nownabe) <a href="https://twitter.com/nownabe/status/1211454178519703552?ref_src=twsrc%5Etfw">December 30, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

# 在職期間

副業で業務委託として 2017 年 1 月から 2017 年 7 月まで、正社員として 2017 年 8 月から 2019 年 12 月まで働いていました。

丸 3 年ですね。思ってたより長い。

# 入社理由

他にもいろいろありますが、こんなところが入社理由でした。

- 業務委託として関わっていたので、どういう課題があって何に取り組めそうかがわかっていた
- 事業責任者が元 CTO で話がめちゃくちゃスムーズだった
- 大学院で学んだ自然言語処理や機械学習の知識をビジネスとして活用できそうだった
- 提示年収が他よりよかった
- 裁量が大きかった
- フルリモートだった

# やったこと

メディアサービスのデータ分析基盤・機械学習系とバックエンド・インフラ系をやりました。
入社時点では主にデータ・機械学習系をやる予定でしたが、小さい組織で他にできる人がいないということでバックエンドとインフラもやりました。

## データ分析基盤・機械学習系

データ分析基盤の構築や、機械学習プロジェクトの開発やリードをしました。
今まで仕事でやったことがないようなことが多く、楽しかったし勉強にもなりました。
また、大学院で学んだ自然言語処理と機械学習の知識を業務で活用することができました。
研究者としてやっていくには全然足りない知識でしたが、ビジネスだと課題によっては雰囲気で実用的なものが作れたので安心したし楽しかったです。

こんなことをやりました。

### データ分析基盤系

#### Cloud Dataflow や App Engine を使ったデータパイプラインの構築

Cloud Dataflow でデータパイプラインを構築し、補助的なアプリケーションを App Engine アプリとして実装しました。

Dataflow がまだそんなに成熟してない頃でした。
Python の SDK ではできないことが多かったので Java や Kotlin で書きました。
App Engine アプリは Java や Go で書きました。

謎のエラーが発生したり(クラウド側の問題だった)、SDK の寿命が短かったり、たまに失敗したり、いろいろ大変な部分もありましたが、新しいパラダイムなプログラミングができて楽しかったです。
業務で初めて Java/Kotlin をフルスクラッチで書いたり Dataflow 使ったり App Engine 使ったり、Dataflow のパラダイムでプログラミングしたりするのは学びも多かったです。

#### Jupyter 基盤の構築

Jupyter でデータ分析したり機械学習いろいろ試したりする基盤を構築しました。

はじめは Cloud Datalab で構築しようとしましたが、まだ発表されたばかりで要件を満たせなかったのでやめました。
最終的に、開発者専有の Compute Engine のインスタンスを作成し、その VM 上に Docker コンテナで Jupyter を展開するという感じの構成になりました。

開発者専有なので、インスタンスを自動作成・構築するようなスクリプトを用意して、誰でも分析基盤を使えるようにしました。

VM の構築は GCE の startup script として実装しました。
それまで VM のプロビジョニングには Chef、Ansible、Itamae を使うことが多かったんですが、結局 Bash でコマンドを叩いて自分で not_if を定義するみたいな操作が多くなりそうだったので Bash スクリプトを採用しました。
また、Jupyter 自体は別に Dockerfile として作っていて VM へのプロビジョニングが不要だったというのも理由です。

筋肉 Bash スクリプト書くのは楽しかったし、使いたかった Cloud KMS を上手く使って自動化できたのも気持ちよかったです。
healthcheck 用のサーバを起動して gcloud コマンドで LB を作って Let's Encrypt で証明書とって Nginx を起動するみたいな処理があって苦労した部分だったんですが、gcloud コマンドで LB を作っといたおかげでその後 Terraform で構築したり GKE で Ingress 使ったりが楽にできるようになりました。

### 機械学習系

#### 機械学習 API 基盤構築

学習済みの機械学習モデルによる Prediction API を動かすための基盤を構築しました。

Go、Python、Kubernetes Engine、Cloud Endpoint、Cloud Storage、Stackdriver Trace、gRPC、Let's Encrypt、らへんの技術スタックで構築しました。
その頃は GCE の LB が HTTP/2 に対応してなかったり、Managed Certificate がなかったりで苦労しました。
ゼロからの構築だったので、使いたい技術を使えて楽しかったです。

また、メインの Rails アプリから使えるように Rails 側のクライアントを Ruby で書いたりもしました。

#### 類似画像検索エンジン開発

検索エンジンというほどのものではないんですが、入力画像から類似画像を検索するシステムを開発しました。
簡単な仕組みで、画像の物体認識ラベルのスコアを元に類似度が高い画像を引っ張ってくるというものです。

Python で実装した後に高速化のため Go で書き直しました。

#### 記事カテゴリ分類 API 開発

メディアに掲載する記事のカテゴリを予測する機械学習モデルを作成しました。
また、そのモデルを使って予測を行う API を開発しました。

大学院修了してから 5 年ぐらい経ってましたが、かろうじて覚えてた知識や学び直した知識が一番活きたプロジェクトでした。
それなりの精度で分類できるモデルをそれなりにスムーズに作れたので、研究の経験は無駄ではなかったんだという体験ができてよかったです。

#### 機械学習チームの立ち上げとリード

機械学習プロジェクトをやっていくチームを立ち上げ、チームのリードをしました。

といっても機械学習の専門家を集めたわけではなく、バックエンドやフロントエンドは一通りサクッとできて、機械学習も学習しつつ実装していけば専門家には及ばなくても今ある課題は解決できるであろう、任せておけば勝手にいいものを作ってくれるエンジニア 2 人にお願いして入ってもらいました。
最高のチームだったんですが、いろいろあって解散になってしまいました。

3 人で議論したり、模索しながら開発したりして、Wondershake で唯一「チーム」として活動したプロジェクトでした。

解散したことも含めて、多くの機械学習プロジェクトあるある失敗を踏めたのでいい経験になりました。

## バックエンド・インフラ系

他にやる人がいない、見える人がいない、できる人がいない、らへんの理由からバックエンドやインフラの仕事もしました。
バックエンドでは、Rails アプリのビジネスロジックではない部分の面倒を見たり、その他のバックエンドアプリの面倒をみたり、開発環境やデプロイまわりなどの足回りを整えたりしました。
インフラでは、障害対応、オンコール体制の整備、監視、セキュリティインシデント対応、ステージング構築とか運用も含めてなんかいろいろしました。

一番目立つかつ大きな仕事としてサービスのインフラを AWS から GCP に移行しました。
これについては以前詳しい記事を書きました。

[よくしらん Rails アプリとかを AWS のレガシーシステムから GCP のイケイケシステムに移行した話](https://blog.nownabe.com/2019/05/21/migration-to-gcp.html/)

移行前は古いインフラで OpsWorks を使って Chef で構築されてたんですが、デプロイが高確率で失敗するとか、インスタンスの OS が古すぎてセキュリティパッチが当てられないとか、Chef がエラーで実行できないとか、インスタンスが人手で変更されてるとかとかとかとか…大変でした。
インフラ移行するみたいな仕事だと、効果が見えにくいので社内から「なにそれ意味あんの？」みたいなこと言われがちだと思うんですが、終わった後にはそんなことも言われず多くの人に感謝されるぐらいには壊れてるインフラでした。

バックエンドは Go や AWS 関係のタスクもありましたが、Rails に関するものが多かったです。
パフォーマンスチューニングやバグ対応なんかの細々したものや、API バージョニングの変更、jbuilder 廃止なんかをやりました。

# 退職理由

書けるものを書くとこんな感じです。

### 元 CTO な事業責任者がいなくなった

前述したとおり元 CTO な事業責任者がいたのが大きな入社理由だったんですが、いなくなっていろいろ変化してしまいました。
そのあとに努力して組織をよくせんかいって声が聞こえてきそうですが、組織や人を変えることに対するリターンってよっぽどのことがない限り労力に見合わないのは学習済みなので、その後はほそぼそと生きていました。

あのときの会社の状況から辞めたことは無責任だとは思わなかったし、いろいろ面白い仕事をさせてもらったので元 CTO には感謝してます。

### 自分の能力低下を感じた

なんというか、脳みそが衰えた感じです。キレがなくなったというか。

集中力の持続時間、選択肢の展開スピード、選択肢の選択スピード、脳内で見える様々な設計の解像度、が低下した気がしています。
コード書いてる時とは別種のアレです。

年齢のせいだとどうしようもないんですが、一番大きい原因は会話してないことじゃないかなーと考えています。
今までを思い返すと脳みそが全開で働いているのを感じたのって誰かと会話していたときが多いんですよね。

特に後半 1 年半は自分の仕事については誰とも相談することなくほぼ 1 人で仕事をしていたので、口から出しながら脳みそを整理するみたいなこともできませんでした。

### やりきった感がでた

インフラ移行が終わって、やりきった感に支配されました。
事業責任者が変わって外から面白そうなタスクが降ってくることもなくなったところへのやりきった感でした。

もちろんその後も自分で仕事を見つけてやってたんですが、プロダクトは安定してしまって大きな変化はなさそうだし、これからも孤独に仕事するのか？みたいなことを考えるといい区切りかなと感じていました。

### 成長曲線が下がってきた

難しくてやりがいがあり、成長できるタスクも多かったんですが、インフラ移行以降は簡単だが手間がかかり面白くないタスクも多々ありました。
そういうタスクの比率が上がってきて、成長を感じにくくなった気がします。

### 良い機会を得た

そういうタイミングで良いオポがありました。

# おわりに

短く終わらせるつもりが長くなってしまいました。

辞めるときは、あー無駄な 3 年間だったみたいな感情もありましたが、振り返ると全然無駄ではなかったですね。振り返ってよかった。

機械学習を初めて業務としてできたのもよかったし、何よりインフラ移行という大仕事をやり遂げられたのは最高でした。

というか、退職エントリ書いてこうやって振り返るのいいですね。
以前は会社辞めるときっていろんな感情があったので退職エントリ書いてなかったんですが、書いておけばよかった…。

あ、勘違いさせてしまうかもしれないので補足しておくと、以前在籍した会社に特に悪い感情は持ってないし、応援してます。

来年 1 月から次の会社なので、次もがんばります！
