---
date: 2018-06-06T19:40:14+0900
lastmod: 2018-06-06T19:40:14+0900
tags: ["nlp", "言語処理のための機械学習入門", "機械学習勉強会", "ml"]
draft: false
isCJKLanguage: true

title: "言語処理のための機械学習入門 第14回"
category: Log

created_at: 2018-06-06 19:40:14 +0900
updated_at: 2018-06-06 19:40:14 +0900
number: 1322
---

[nownab.log | 言語処理のための機械学習入門 第13回](https://blog.nownabe.com/2018/05/30/1315.html)

# 概要
機械学習勉強会で輪読してる[言語処理のための機械学習入門](http://amzn.to/2BFQSee)の学習メモです。
勉強会用の資料があるのでこちらでは資料に載らなかったメモ等を。

# 資料置き場

[14回目 4.4 カーネル法 · Issue #97 · Wondershake/machine-learning-study](https://github.com/Wondershake/machine-learning-study/issues/97)

# 範囲
* 4 分類
    * 4.4 カーネル法

# 4 分類
## 4.4 カーネル法

木構造カーネルも文字列カーネルも知らなかった。
ベクトル化せずに内積を求めるカーネルってことで、実用的にはあんまり使う機会はないのかな。

カーネル法が愚直にやるより高速って言われるのは、次の2つの理由から？カーネルトリックっていったときは後者を指すんだろうか。

* 木構造カーネルや文字列カーネルでは、事例をベクトル化せずに内積を求められるので高速
* 例えば多項式カーネルだと事例の次元数を増やすと考えたとき、各事例に対して$\phi(\boldsymbol{x})=(x_1^2,x_2^2,\sqrt 2x_1x_2,\sqrt 2x_1,\sqrt 2x_2, 1)$を計算した後に内積をとる必要はなく、各事例の組み合わせに対して$K_{poly},d=(\boldsymbol{x}^{(i)}\cdot\boldsymbol{x}^{(j)}+1)^d$を計算すれば同じ結果が得られるので高速

# 所感

* 例題が実際に多項式カーネルを使ってSVMを学習していて、とても参考になる

# 言語処理のための機械学習入門
<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=nownabe0c-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=4339027510&linkId=1c6291b86381f20d113796257356ef1b"></iframe>

# 機械学習勉強会について
社内で毎週開催している。本書は輪読形式でまわしているが、題材によって形式は柔軟に変えている。
毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。

また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。
[Wondershake/machine-learning-study: 機械学習勉強会](https://github.com/Wondershake/machine-learning-study)

```math
```
