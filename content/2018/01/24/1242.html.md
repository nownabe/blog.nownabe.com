---
date: 2018-01-22T17:51:33+0900
lastmod: 2018-01-24T21:39:57+0900
tags: ["機械学習勉強会", "Python機械学習プログラミング"]
draft: false
isCJKLanguage: true

title: "Python機械学習プログラミング  第4章"
category: Log

created_at: 2018-01-22 17:51:33 +0900
updated_at: 2018-01-24 21:39:57 +0900
published: true
number: 1242
---

# 概要
Python機械学習プログラミングの学習メモです。
勉強会用の資料があるのでこちらでは資料に載らなかったメモ等を。

今回は、第4章 データ前処理 - よりよいトレーニングセットの構築

前回: [nownab.log | Python機械学習プログラミング 第3章](https://blog.nownabe.com/2018/01/17/1240.html)

# 資料
* [4.1-4.4](https://gitpitch.com/mmyoji/slides/python-ml-3rd#/)
* [4.5-4.6](https://nownabe.github.io/slides/20180125-python-ml-ch04/index.html#/)

# 環境

本書の各バージョンは結構古いので、できるだけ新しいバージョンを使うようにしている。

* Python 3.6.4
* scikit-learn 0.19.1
* matplotlib 2.1.1

# メモ
## 4.1 欠測データへの対処
### 4.1.1 欠測値を持つサンプル / 特徴量を取り除く
### 4.1.2 欠測値を補完する
### 4.1.3 scikit-learnの推定器API

## 4.2 カテゴリデータの処理
### 4.2.1 順序特徴量のマッピング
### 4.2.2 クラスラベルのエンコーディング

`enumerate`[^1]は組み込み関数で、Rubyの`Enumerator#with_index`[^2]と同じような感じっぽい。

[^1]: https://docs.python.jp/3/library/functions.html#enumerate
[^2]: https://docs.ruby-lang.org/ja/latest/class/Enumerator.html#I_WITH_INDEX

`LabelEncoder`クラスの`inverse_transform`メソッドを使うと次のDeprecation Warningが発生した。

```
DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
```

どうやらバグらしくmasterブランチでは修正が入っているがリリースはされていない。[^3]

[^3]: [[MRG + 1] Fix ValueError in LabelEncoder when using inverse_transform on unseen labels by newey01c · Pull Request #9816 · scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn/pull/9816)

### 4.2.3 名義特徴量での one-hot エンコーディング

## 4.3 データセットをトレーニングデータセットとテストデータセットに分割する

## 4.4 特徴量の尺度を揃える

多くの機械学習アルゴリズムは正規化より標準化の方が実用的らしい。ほう。

重みを小さな乱数で初期化するから標準化の方がいいって説明はよくわからんが、正規化は外れ値の影響を受けやすいってのはなんとなくわかる。

## 4.5 有益な特徴量の選択
### 4.5.1 L1正則化による疎な解
### 4.5.2 逐次特徴選択アルゴリズム

indicesはindexの複数形！！！今までindexesって書いてた :innocent: 

Pythonは組み込み関数が多かったりしてややこしい。

```python
>>> dim = 5
>>> tuple(range(5))
(0, 1, 2, 3, 4)
```

## 4.6 ランダムフォレストで特徴量の重要度にアクセスする

argxxx系の関数は便利だなー。スライスへの理解が深まった。[^4][^5][^6]

[^4]: https://docs.python.jp/3/library/functions.html#slice
[^5]: https://docs.python.jp/3/glossary.html#term-slice
[^6]: https://docs.python.jp/3/library/stdtypes.html#common-sequence-operations ここの注釈が一番くわしい


```python
>>> import numpy as np
>>> arr = np.array([1, 3, 5, 4, 2])
>>> np.argsort(arr)
array([0, 4, 1, 3, 2])
>>> arr[::-1]
array([2, 4, 5, 3, 1])
>>> arr[::0]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: slice step cannot be zero
>>> arr[::1]
array([1, 3, 5, 4, 2])
>>> arr[::2]
array([1, 5, 2])
>>> arr[::3]
array([1, 4])
>>> arr[::5]
array([1])
>>> arr[::6]
array([1])
>>> arr[::-1]
array([2, 4, 5, 3, 1])
>>> arr[::-2]
array([2, 5, 1])
```

文字列の書式指定がよくわからなかったので調べた。[ドキュメント](https://docs.python.jp/3/library/string.html#format-specification-mini-language)にも書いてない。

```python
print("%2d) %-*s %f" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))
```

特に`%-*s`の部分と、`%`の個数と値の数があってない部分。

どうやら、次の2つのコードは同じ意味らしい。

```python
"%-*s" % (30, "hoge")
"%-30s" % ("hoge")
```

で、`%`の直後のハイフンは左詰めという意味らしい。

```python
>>> "%-*s" % (30, "hoge")
'hoge                          '
>>> "%-30s" % ("hoge")
'hoge                          '
>>> "%*s" % (30, "hoge")
'                          hoge'
```

Bashのprintfでもできた。ほー、知らなかった。

```bash
$ printf "%-*s@\n" 30 hoge
hoge                          @
$ printf "%*s@\n" 30 hoge
                          hoge@
$ printf "%-*d@\n" 30 1
1                             @
$ printf "%*d@\n" 30 1
                             1@
$ printf "%*d@\n" 20 1
                   1@
```

`transform`メソッドないやんけ！と思ったら注釈に書いてあった。

```python
from sklearn.feature_selection import SelectFromModel

sfm = SelectFromModel(rf, prefit=True, threshold=0.15)
X_selected = sfm.transform(X_train)
print(X_selected.shape)
```

# Python機械学習プログラミング
<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=nownabe0c-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=B01HGIPIAK&linkId=ef8aa25f336a01f62b00fce21e6f952a"></iframe>

# 機械学習勉強会について
社内で毎週開催している。本書は輪読形式でまわしているが、題材によって形式は柔軟に変えている。
毎週読む範囲を決めて資料にまとめて発表するという感じでやっている。

また、勉強会で書いたコードや疑問点などをまとめるためにGitHubのレポジトリを活用している。
[Wondershake/machine-learning-study: 機械学習勉強会](https://github.com/Wondershake/machine-learning-study)

```math
```
